{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Eye-State Based on EEG Data #\n",
    "### Traditional Classification Neural Networks vs convolutional Neural Networks ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Anthony Feudale, October 27, 2021*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguably one of the most exciting aspects of machine learning is its potential use for taking over certain types of cognitive work. Neural networks have made highly cognitive tasks, such as identifying objects in images, computational tasks as opposed to tasks which previously only humans could do. The accuracy and speed of such methods has proven to be game changing in some cases.</br>\n",
    "\n",
    "A large part of what people do on a day-to-day basis in today's economy is cognitive work. While machine learning is highly limited in its scope (machine learning algorithms can only handle narrowly constrained tasks) it can serve to amplify the amount of work people are able to accomplish. No potential usage of machine learning better highlights this then Brain-Computer Interfaces or BCIs. Currently the ability of people to work with machines is mediated through devices like keyboards, mice, and touchscreens. All of these rely on direct physical manipulation to interface with a computer. Not everybody has full use of their limbs and these people have significant difficulty in using computers. New technologies like  speech-to-text powered by machine learning have made large gains in  ameliorating this problem. Additionally, traditional computer interfaces limit the speed with which people can interact with their devices. You can only code or write only as fast as you can type, which can be a severe limitation for some individuals. Additionally, increasing the speed with which we interface with computers could serve to spark a quantum leap in humanity's productive capacity similar to the explosion in human knowledge brought about by the proliferation of knowledge via the printing press or the Internet [T. Urban, 2017]. Direct Brain-Computer Interfaces could help close this speed gap, and light the match for another such explosion.</br>\n",
    "\n",
    "One Potential Avenue for BCIs is the EEG or Electroencephalogram [Johns Hopkins, 2021]. Via electrical sensors placed on the scalp this device senses changes in electrical impulses coming from the brain. Unfortunately, such signals are quite noisy and can be hard to interpret. This is where machine learning comes in. Using machine learning techniques it is possible to utilize EEG signals to detect when a user wants to do a particular action. For example, closing one's eyes, and the resulting changes in EEG activity, could signal that a user wants to \"click\" as if they were clicking the mouse button on a physical mouse. </br>\n",
    "\n",
    "I found this idea intriguing and so decided to investigate it as part of my final project. I looked through various EEG data sets. A fair number of such sets exist. Many deal with motor imagery, emotion recognition, various potentials, and movement [Meagmohit, 2020]. After reviewing several data sets I eventually settled on one from the UCI Machine Learning Repository regarding eye-state [O. Roesler, 2013]. I did so because I could envision eye-state being used as an early means of interfacing with a computer and because the data was well curated for the learning task I had planned. I intend to utilize both a traditional classification neural network as well as a convolutional neural network to attempt to determine eye-state from this EEG data. I will utilize PyTorch to do so [A. Paszke, S. Gross, S. Chantala, and G. Chanan, 2021]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset I will be working with is from the UCI Machine Learning Repository, and is in regard to eye-state (open or closed) [O. Roesler, 2013]. It is one continuous time series. 14 EEG channels were captured over the course of 117 seconds for a total of 14,980 instances. For each instance, eye-state was captured via a camera and later manually added to the data set as  a 15th column where '0' indicates the eye-open state and 1' indicates the eye-closed state. The data file is in .arff format. I will convert this into .csv and then create new .csv files for train, validation, and test data by random selection from the main dataset. </br>\n",
    "\n",
    "I will utilize PyTorch to train two separate models to predict eye-state based on the 14 EEG channels. I intend to utilize both a traditional classification neural network as well as a convolutional neural network. In both cases I will vary things like layer structure, learning rates, methods, and training epochs to try and find an optimal network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Milestones</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | Milestone | Description \n",
    "| :- | :- | :- |\n",
    "| 11/5 | Project Proposal | Complete research on topic, methods, and data. Hand in final project proposal\n",
    "| 11/12 | Complete Preliminary Coding | Implement initial code for training of data\n",
    "| 11/19 | Complete Final Coding and Training Experiments | Work through training data with various methods. Find what is most accurate without over-training\n",
    "| 11/26 | Complete Preliminary Report | Complete preliminary report including data from training\n",
    "| 12/12 | Final Project Complete | Hand in final project, including finalized report, data, and project files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect my results to be different between the two network types. Given the high frequency of noise which is typical in EEG data, I expect the traditional classification neural network to have trouble accurately classifying eye-state. Given that I only have about 15,000 samples I expect it will take a significant amount of training to get the traditional classification neural network to a decent accuracy on train and validation data. I fully expect that this will not generalize particularly well to the test data as I expect the traditional classification neural network will need to over-fit in order to predict the training data well. </br>\n",
    "\n",
    "On the other hand I expect the convolutional neural network to do a better job of generalizing. Given that EEG signals can be thought of as continuous waves, I expect that convolving over time will allow the convolutional neural network to pick out important features in the data that are only present when viewed over time. I believe this will give the convolutional neural network a greater advantage in correctly discriminating eye-state over the traditional classification neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect that I will learn a great deal about the intricacies in setting up networks, such as properly convolving single dimensional time series data. I expect I will also get an object lesson in the problems that often arise when trying to get a neural network to learn from a noisy data set. I will be interested to see if the relatively small size of my data set has a deleterious impact on each neural network's ability to learn. I hope I learn that 15,000 samples can be enough, but we will see.</br>\n",
    "\n",
    "While many aspects of this project will be challenging, I expect the most challenging piece will be identifying the parameters which best allow the neural networks to correctly classify eye-state. I expect this to take many attempts and involve a lot of trial and error. Second place in terms of challenge will likely be getting the neural networks set up to run at all initially. This will probably take some time, but it will likely be easier due to the plethora of material and tutorials on PyTorch available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [T. Urban, 2017] T. Urban, “Neuralink and the brain's magical future,” Wait But Why, 20-Apr-2017. [Online]. Available: https://waitbutwhy.com/2017/04/neuralink.html. [Accessed: 29-Oct-2021]. \n",
    "* [Johns Hopkins, 2021] Johns Hopkins, “Electroencephalogram (EEG),” Johns Hopkins Medicine, 2021. [Online]. Available: https://www.hopkinsmedicine.org/health/treatment-tests-and-therapies/electroencephalogram-eeg. [Accessed: 29-Oct-2021]. \n",
    "* [Meagmohit, 2020] Meagmohit, “Meagmohit/EEG-datasets: A list of all public EEG-datasets,” GitHub, 23-Nov-2020. [Online]. Available: https://github.com/meagmohit/EEG-Datasets. [Accessed: 29-Oct-2021]. \n",
    "* [O. Roesler, 2013] O. Roesler, “EEG eye-state Data Set,” UCI Machine Learning Repository: Eeg eye-state Data set, 10-Jun-2013. [Online]. Available: https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State. [Accessed: 29-Oct-2021]. \n",
    "* [A. Paszke, S. Gross, S. Chantala, and G. Chanan, 2021] A. Paszke, S. Gross, S. Chantala, and G. Chanan, “Pytorch/Pytorch: Tensors and dynamic neural networks in python with strong GPU acceleration,” GitHub, 29-Oct-2021. [Online]. Available: https://github.com/pytorch/pytorch. [Accessed: 29-Oct-2021]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T14:49:15.869360Z",
     "start_time": "2021-10-27T14:49:15.860735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count for file Feudale_Final_Project_Proposal.ipynb is 1315\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import nbformat\n",
    "import glob\n",
    "\n",
    "nbfile = glob.glob(\"Feudale_Final_Project_Proposal.ipynb\")\n",
    "if len(nbfile) > 1:\n",
    "    print(\"More than one ipynb file. Using the first one.  nbfile=\", nbfile)\n",
    "with io.open(nbfile[0], \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = nbformat.read(f, nbformat.NO_CONVERT)\n",
    "word_count = 0\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell[\"source\"].replace(\"#\", \"\").lstrip().split(\" \"))\n",
    "print(\"Word count for file\", nbfile[0], \"is\", word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp",
   "language": "python",
   "name": "fp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
