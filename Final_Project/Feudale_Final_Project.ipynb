{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "334a04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c49f5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import finalprojectneuralnetworks as fpnn\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087f60f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "\n",
    "# with open(\"Dummy_Validate.csv\", \"w\", newline=\"\") as csvfile:\n",
    "#     spamwriter = csv.writer(\n",
    "#         csvfile, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n",
    "#     )\n",
    "#     col_labels = [\n",
    "#         \"AF3\",\n",
    "#         \"F7\",\n",
    "#         \"F3\",\n",
    "#         \"FC5\",\n",
    "#         \"T7\",\n",
    "#         \"P7\",\n",
    "#         \"O1\",\n",
    "#         \"O2\",\n",
    "#         \"P8\",\n",
    "#         \"T8\",\n",
    "#         \"FC6\",\n",
    "#         \"F4\",\n",
    "#         \"F8\",\n",
    "#         \"AF4\",\n",
    "#         \"eyeDetection\",\n",
    "#     ]\n",
    "#     spamwriter.writerow(col_labels)\n",
    "#     list_a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0]\n",
    "#     list_b = [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 1]\n",
    "#     for i in range(500):\n",
    "#         random_number = random.randint(1, 10)\n",
    "#         if random_number > 5:\n",
    "#             spamwriter.writerow(list_a)\n",
    "#         else:\n",
    "#             spamwriter.writerow(list_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e029db25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# root_directory = 'D:\\College\\CS_545\\Final_Project'\n",
    "# fp_csv_file = 'EEG_Eye_State.csv'\n",
    "# train_fraction = 0.8\n",
    "# validate_fraction = 0.1\n",
    "# X = pd.read_csv(os.path.join(root_directory,fp_csv_file), delimiter=',', usecols=range(15)).dropna(axis=0).to_numpy()\n",
    "# n_samples = X.shape[0]\n",
    "# rows = np.arange(n_samples)\n",
    "# np.random.shuffle(rows)\n",
    "\n",
    "# n_train = round(n_samples * train_fraction)\n",
    "# n_validate = round(n_samples * validate_fraction)\n",
    "\n",
    "# col_labels = [\"AF3\",\"F7\",\"F3\",\"FC5\",\"T7\",\"P7\",\"O1\",\"O2\",\"P8\",\"T8\",\"FC6\",\"F4\",\"F8\",\"AF4\",\"eyeDetection\"]\n",
    "# Xtrain = X[rows[:n_train], :]\n",
    "# Xvalidate = X[rows[n_train:n_train + n_validate], :]\n",
    "# Xtest = X[rows[n_train + n_validate:], :]\n",
    "# Xtrain = pd.DataFrame(Xtrain, columns = col_labels)\n",
    "# Xvalidate = pd.DataFrame(Xvalidate, columns = col_labels)\n",
    "# Xtest = pd.DataFrame(Xtest, columns = col_labels)\n",
    "# Xtrain = Xtrain.astype({\"eyeDetection\": int})\n",
    "# Xvalidate = Xvalidate.astype({\"eyeDetection\": int})\n",
    "# Xtest = Xtest.astype({\"eyeDetection\": int})\n",
    "# print(Xtrain.iloc[0])\n",
    "# print( type(X))\n",
    "# Xtrain.to_csv(\"EEG_Eye_State_Train.csv\", encoding='utf-8', index_label=False, index=False, quoting=csv.QUOTE_NONNUMERIC )\n",
    "# Xvalidate.to_csv(\"EEG_Eye_State_Validate.csv\", encoding='utf-8', index_label=False, index=False, quoting=csv.QUOTE_NONNUMERIC )\n",
    "# Xtest.to_csv(\"EEG_Eye_State_Test.csv\", encoding='utf-8', index_label=False, index=False, quoting=csv.QUOTE_NONNUMERIC )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb987a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3             4309.74\n",
      "F7              4052.82\n",
      "F3              4285.13\n",
      "FC5             4155.38\n",
      "T7              4369.23\n",
      "P7              4646.67\n",
      "O1              4100.00\n",
      "O2              4649.74\n",
      "P8              4221.54\n",
      "T8              4230.26\n",
      "FC6             4206.15\n",
      "F4              4292.82\n",
      "F8              4598.97\n",
      "AF4             4362.56\n",
      "eyeDetection       0.00\n",
      "Name: 0, dtype: float64\n",
      "0\n",
      "[[4309.74 4052.82 4285.13 4155.38 4369.23 4646.67 4100.   4649.74 4221.54\n",
      "  4230.26 4206.15 4292.82 4598.97 4362.56]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11984, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_directory = \"D:\\College\\CS_545\\Final_Project\"\n",
    "# root_directory = \"/s/chopin/l/grad/acf003/CS_545\"\n",
    "fp_csv_file = \"EEG_Eye_State_Train.csv\"\n",
    "# fp_csv_file = \"Dummy_Train.csv\"\n",
    "eeg_data = pd.read_csv(\n",
    "    os.path.join(root_directory, fp_csv_file), delimiter=\",\", usecols=range(15)\n",
    ").dropna(axis=0)\n",
    "\n",
    "print(eeg_data.iloc[0, :])\n",
    "open_or_closed = eeg_data.iloc[0, 14]\n",
    "channel_data = eeg_data.iloc[0, 0:14]\n",
    "channel_data = np.array([channel_data])\n",
    "channel_data = channel_data.astype(\"float\").reshape(-1, 14)\n",
    "print(open_or_closed)\n",
    "print(channel_data)\n",
    "eeg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d7acdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3             float64\n",
      "F7              float64\n",
      "F3              float64\n",
      "FC5             float64\n",
      "T7              float64\n",
      "P7              float64\n",
      "O1              float64\n",
      "O2              float64\n",
      "P8              float64\n",
      "T8              float64\n",
      "FC6             float64\n",
      "F4              float64\n",
      "F8              float64\n",
      "AF4             float64\n",
      "eyeDetection      int64\n",
      "dtype: object\n",
      "AF3             float64\n",
      "F7              float64\n",
      "F3              float64\n",
      "FC5             float64\n",
      "T7              float64\n",
      "P7              float64\n",
      "O1              float64\n",
      "O2              float64\n",
      "P8              float64\n",
      "T8              float64\n",
      "FC6             float64\n",
      "F4              float64\n",
      "F8              float64\n",
      "AF4             float64\n",
      "eyeDetection      int64\n",
      "dtype: object\n",
      "AF3             float64\n",
      "F7              float64\n",
      "F3              float64\n",
      "FC5             float64\n",
      "T7              float64\n",
      "P7              float64\n",
      "O1              float64\n",
      "O2              float64\n",
      "P8              float64\n",
      "T8              float64\n",
      "FC6             float64\n",
      "F4              float64\n",
      "F8              float64\n",
      "AF4             float64\n",
      "eyeDetection      int64\n",
      "dtype: object\n",
      "11984\n"
     ]
    }
   ],
   "source": [
    "root_directory = \"D:\\College\\CS_545\\Final_Project\"\n",
    "# root_directory = \"/s/chopin/l/grad/acf003/CS_545\"\n",
    "\n",
    "train_file = \"EEG_Eye_State_Train.csv\"\n",
    "validate_file = \"EEG_Eye_State_Validate.csv\"\n",
    "test_file = \"EEG_Eye_State_Test.csv\"\n",
    "\n",
    "# train_file = \"Dummy_Train.csv\"\n",
    "# validate_file = \"Dummy_Validate.csv\"\n",
    "# test_file = \"Dummy_Test.csv\"\n",
    "\n",
    "train_dataset = fpnn.FinalProjectEEGDataset(train_file, root_directory)\n",
    "validate_dataset = fpnn.FinalProjectEEGDataset(validate_file, root_directory)\n",
    "test_dataset = fpnn.FinalProjectEEGDataset(test_file, root_directory)\n",
    "print(train_dataset.__len__())\n",
    "train_dataset.__getitem__(0)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "validate_dataloader = DataLoader(validate_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a360238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c653ec23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = fpnn.NeuralNetwork(28 * 28, [512, 512], 10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aceb2dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0108, -0.1030,  0.0752,  0.0014,  0.0153, -0.0424,  0.0872, -0.0424,\n",
      "         -0.0297,  0.0263]], grad_fn=<AddmmBackward>)\n",
      "Predicted class: tensor([6])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "print(logits)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55e5e4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    # first = True\n",
    "    for batch, (X, T) in enumerate(dataloader):\n",
    "        X, T = X.to(device), T.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        Y = model(X.float())\n",
    "        # if first:\n",
    "        #     first = False\n",
    "        #     print('Y.shape', Y.shape)\n",
    "        #     print('T.shape', T.shape)\n",
    "        #     print('T: ', T[0])\n",
    "        loss = loss_fn(Y, T.long())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "#         if batch % 50 == 0:\n",
    "#             loss, current = loss.item(), batch * len(X)\n",
    "# print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17432e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, T in dataloader:\n",
    "            X, T = X.to(device), T.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, T.long()).item()\n",
    "            correct += (pred.argmax(1) == T).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32ade0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_epochs(\n",
    "    epochs, train_dataloader, vaidate_dataloader, model, loss_fn, optimizer\n",
    "):\n",
    "    start = time.time()\n",
    "    for t in range(epochs):\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        if t % 100 == 0:\n",
    "            print(f\"Epoch {t}\\n-------------------------------\")\n",
    "            test(validate_dataloader, model, loss_fn)\n",
    "    end = time.time()\n",
    "    print(\"Done: \", end - start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41ba2342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fashion_training_data = datasets.FashionMNIST(\n",
    "#     root=\"data\",\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=ToTensor(),\n",
    "# )\n",
    "# fashion_train_dataloader = DataLoader(fashion_training_data, batch_size=64)\n",
    "# n_samples, n_inputs = train_dataset.__len__(), 28*28\n",
    "# n_outputs = 1\n",
    "# n_hiddens = [10, 10]\n",
    "# model = fpnn.NeuralNetwork(28*28, n_hiddens, 10).to(device)\n",
    "# print(model)\n",
    "\n",
    "# learning_rate = 0.5 / (n_samples * n_outputs)  ## Larger learning rate\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# train(fashion_train_dataloader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3190dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 14])\n",
      "Shape of y:  torch.Size([64]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082909f-a936-4f85-9713-3da18371ea33",
   "metadata": {},
   "source": [
    "I started out with a dummy run using dummy data that had a trivial pattern which the neural network should easily be able to learn. I did this to simply test that the network was correctly setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "319f87a6-a129-4ecf-b550-4e3a60b4cfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3             int64\n",
      "F7              int64\n",
      "F3              int64\n",
      "FC5             int64\n",
      "T7              int64\n",
      "P7              int64\n",
      "O1              int64\n",
      "O2              int64\n",
      "P8              int64\n",
      "T8              int64\n",
      "FC6             int64\n",
      "F4              int64\n",
      "F8              int64\n",
      "AF4             int64\n",
      "eyeDetection    int64\n",
      "dtype: object\n",
      "AF3             int64\n",
      "F7              int64\n",
      "F3              int64\n",
      "FC5             int64\n",
      "T7              int64\n",
      "P7              int64\n",
      "O1              int64\n",
      "O2              int64\n",
      "P8              int64\n",
      "T8              int64\n",
      "FC6             int64\n",
      "F4              int64\n",
      "F8              int64\n",
      "AF4             int64\n",
      "eyeDetection    int64\n",
      "dtype: object\n",
      "AF3             int64\n",
      "F7              int64\n",
      "F3              int64\n",
      "FC5             int64\n",
      "T7              int64\n",
      "P7              int64\n",
      "O1              int64\n",
      "O2              int64\n",
      "P8              int64\n",
      "T8              int64\n",
      "FC6             int64\n",
      "F4              int64\n",
      "F8              int64\n",
      "AF4             int64\n",
      "eyeDetection    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "root_directory = \"D:\\College\\CS_545\\Final_Project\"\n",
    "# root_directory = \"/s/chopin/l/grad/acf003/CS_545\"\n",
    "\n",
    "# train_file = \"EEG_Eye_State_Train.csv\"\n",
    "# validate_file = \"EEG_Eye_State_Validate.csv\"\n",
    "# test_file = \"EEG_Eye_State_Test.csv\"\n",
    "\n",
    "train_file = \"Dummy_Train.csv\"\n",
    "validate_file = \"Dummy_Validate.csv\"\n",
    "test_file = \"Dummy_Test.csv\"\n",
    "\n",
    "train_dataset = fpnn.FinalProjectEEGDataset(train_file, root_directory)\n",
    "validate_dataset = fpnn.FinalProjectEEGDataset(validate_file, root_directory)\n",
    "test_dataset = fpnn.FinalProjectEEGDataset(test_file, root_directory)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "validate_dataloader = DataLoader(validate_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9189f641-75c4-4724-a1ff-02c0a6df3a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=14, out_features=5, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=5, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.763841 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033209 \n",
      "\n",
      "Done:  17.03054141998291  seconds\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_inputs = train_dataset.__len__(), 14\n",
    "n_outputs = 2\n",
    "n_hiddens = [5, 5]\n",
    "model = fpnn.NeuralNetwork(n_inputs, n_hiddens, n_outputs).to(device)\n",
    "print(model)\n",
    "\n",
    "# learning_rate = 0.05 / (n_samples * n_outputs)\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 101\n",
    "train_for_epochs(\n",
    "    epochs, train_dataloader, validate_dataloader, model, loss_fn, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28130031-3767-4640-8111-bb30cf31dd73",
   "metadata": {},
   "source": [
    "Unsurprisingly in this dummy run the model learned to predict with 100% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788dca1-9457-40d3-9e4b-8b2ff7667588",
   "metadata": {},
   "source": [
    "I then moved on to the actual data to see what kind of accuracy I could get from a classical classification neural network model. I tried several structures and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "186cd8ca-6ec0-4ab1-8758-9aae7df8b876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3             float64\n",
      "F7              float64\n",
      "F3              float64\n",
      "FC5             float64\n",
      "T7              float64\n",
      "P7              float64\n",
      "O1              float64\n",
      "O2              float64\n",
      "P8              float64\n",
      "T8              float64\n",
      "FC6             float64\n",
      "F4              float64\n",
      "F8              float64\n",
      "AF4             float64\n",
      "eyeDetection      int64\n",
      "dtype: object\n",
      "AF3             float64\n",
      "F7              float64\n",
      "F3              float64\n",
      "FC5             float64\n",
      "T7              float64\n",
      "P7              float64\n",
      "O1              float64\n",
      "O2              float64\n",
      "P8              float64\n",
      "T8              float64\n",
      "FC6             float64\n",
      "F4              float64\n",
      "F8              float64\n",
      "AF4             float64\n",
      "eyeDetection      int64\n",
      "dtype: object\n",
      "AF3             float64\n",
      "F7              float64\n",
      "F3              float64\n",
      "FC5             float64\n",
      "T7              float64\n",
      "P7              float64\n",
      "O1              float64\n",
      "O2              float64\n",
      "P8              float64\n",
      "T8              float64\n",
      "FC6             float64\n",
      "F4              float64\n",
      "F8              float64\n",
      "AF4             float64\n",
      "eyeDetection      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "root_directory = \"D:\\College\\CS_545\\Final_Project\"\n",
    "# root_directory = \"/s/chopin/l/grad/acf003/CS_545\"\n",
    "\n",
    "train_file = \"EEG_Eye_State_Train.csv\"\n",
    "validate_file = \"EEG_Eye_State_Validate.csv\"\n",
    "test_file = \"EEG_Eye_State_Test.csv\"\n",
    "\n",
    "# train_file = \"Dummy_Train.csv\"\n",
    "# validate_file = \"Dummy_Validate.csv\"\n",
    "# test_file = \"Dummy_Test.csv\"\n",
    "\n",
    "train_dataset = fpnn.FinalProjectEEGDataset(train_file, root_directory)\n",
    "validate_dataset = fpnn.FinalProjectEEGDataset(validate_file, root_directory)\n",
    "test_dataset = fpnn.FinalProjectEEGDataset(test_file, root_directory)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "validate_dataloader = DataLoader(validate_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "796d2033-3bac-4f43-be51-a1e49e188983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=14, out_features=5, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=5, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.697316 \n",
      "\n",
      "Done:  20.450348138809204  seconds\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_inputs = train_dataset.__len__(), 14\n",
    "n_outputs = 2\n",
    "n_hiddens = [5, 5]\n",
    "model = fpnn.NeuralNetwork(n_inputs, n_hiddens, n_outputs).to(device)\n",
    "print(model)\n",
    "\n",
    "# learning_rate = 0.05 / (n_samples * n_outputs)\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 10\n",
    "train_for_epochs(\n",
    "    epochs, train_dataloader, validate_dataloader, model, loss_fn, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "211af310-64c5-4c9f-964d-9ec13b2c1bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=14, out_features=10, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 10.459651 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 3.271880 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.862043 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.685989 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.685970 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.685949 \n",
      "\n",
      "Done:  1008.1690013408661  seconds\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_inputs = train_dataset.__len__(), 14\n",
    "n_outputs = 2\n",
    "n_hiddens = [10, 10]\n",
    "model = fpnn.NeuralNetwork(n_inputs, n_hiddens, n_outputs).to(device)\n",
    "print(model)\n",
    "\n",
    "# learning_rate = 0.05 / (n_samples * n_outputs)\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 501\n",
    "train_for_epochs(\n",
    "    epochs, train_dataloader, validate_dataloader, model, loss_fn, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80d29813-9c38-4d11-9fff-51591a825449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=14, out_features=30, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=20, out_features=15, bias=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (Linear3): Linear(in_features=15, out_features=10, bias=True)\n",
      "    (ReLU3): ReLU()\n",
      "    (Linear4): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.173773 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.685931 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.685854 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.685854 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.685854 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.685854 \n",
      "\n",
      "Done:  1033.4101610183716  seconds\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_inputs = train_dataset.__len__(), 14\n",
    "n_outputs = 2\n",
    "n_hiddens = [30, 20, 15, 10]\n",
    "model = fpnn.NeuralNetwork(n_inputs, n_hiddens, n_outputs).to(device)\n",
    "print(model)\n",
    "\n",
    "# learning_rate = 0.05 / (n_samples * n_outputs)\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 501\n",
    "train_for_epochs(\n",
    "    epochs, train_dataloader, validate_dataloader, model, loss_fn, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0647adb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=14, out_features=500, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=500, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 6.962534 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.713657 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.713657 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.713657 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.713657 \n",
      "\n",
      "Done:  1214.9345533847809  seconds\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_inputs = train_dataset.__len__(), 14\n",
    "n_outputs = 2\n",
    "n_hiddens = [500, 500]\n",
    "model = fpnn.NeuralNetwork(n_inputs, n_hiddens, n_outputs).to(device)\n",
    "print(model)\n",
    "\n",
    "# learning_rate = 0.05 / (n_samples * n_outputs)\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 500\n",
    "train_for_epochs(\n",
    "    epochs, train_dataloader, validate_dataloader, model, loss_fn, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59d3a9c2-790c-4189-afa0-71999820f1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=14, out_features=500, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=500, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 288.282979 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 0.785713 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.756815 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.722233 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 0.705566 \n",
      "\n",
      "Done:  1155.8505518436432  seconds\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_inputs = train_dataset.__len__(), 14\n",
    "n_outputs = 2\n",
    "n_hiddens = [500, 500]\n",
    "model = fpnn.NeuralNetwork(n_inputs, n_hiddens, n_outputs).to(device)\n",
    "print(model)\n",
    "\n",
    "# learning_rate = 0.05 / (n_samples * n_outputs)\n",
    "learning_rate = 0.01 / (n_samples * n_outputs)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 500\n",
    "train_for_epochs(\n",
    "    epochs, train_dataloader, validate_dataloader, model, loss_fn, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9571821-5d3d-4dd7-8c10-0ac977e515d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=14, out_features=500, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=500, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss:      nan \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss:      nan \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss:      nan \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss:      nan \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss:      nan \n",
      "\n",
      "Done:  1099.8602554798126  seconds\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_inputs = train_dataset.__len__(), 14\n",
    "n_outputs = 2\n",
    "n_hiddens = [500, 500]\n",
    "model = fpnn.NeuralNetwork(n_inputs, n_hiddens, n_outputs).to(device)\n",
    "print(model)\n",
    "\n",
    "# learning_rate = 0.05 / (n_samples * n_outputs)\n",
    "learning_rate = 0.01 / (n_samples * n_outputs)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 500\n",
    "train_for_epochs(\n",
    "    epochs, train_dataloader, validate_dataloader, model, loss_fn, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bd522c6-9a7e-4118-a2fd-5dee071dce3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=14, out_features=500, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=500, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 77656832.685102 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 77656832.683104 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 77656832.681246 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 77656832.679520 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 77656832.677915 \n",
      "\n",
      "Done:  1064.0559866428375  seconds\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_inputs = train_dataset.__len__(), 14\n",
    "n_outputs = 2\n",
    "n_hiddens = [500, 500]\n",
    "model = fpnn.NeuralNetwork(n_inputs, n_hiddens, n_outputs).to(device)\n",
    "print(model)\n",
    "\n",
    "# learning_rate = 0.05 / (n_samples * n_outputs)\n",
    "learning_rate = 0.01 / (n_samples * n_outputs)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 500\n",
    "train_for_epochs(\n",
    "    epochs, train_dataloader, validate_dataloader, model, loss_fn, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b9ab2-f244-4dfd-8b51-c45a8c7e334f",
   "metadata": {},
   "source": [
    "Unfortunately this approach didn't seem to produce very good results. The models were barely better than chance, with he best of them achieving a final accuracy of 56%. They also didn't seem to learn much after the initial few epochs. I decided to try a different approach going forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020bb429-3120-42a6-827a-04690303d340",
   "metadata": {},
   "source": [
    "## New Approach Experimentation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50c9e6-b442-4021-9db7-15c993e2ba91",
   "metadata": {},
   "source": [
    "I started by removing any glaring outliers from the data. I thought this might make it a little easier for the neural network to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45c6c874-4cc1-459b-ace9-28575ee0e61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14980, 15)\n",
      "[[4329.23 4009.23 4289.23 4148.21 4350.26 4586.15 4096.92 4641.03 4222.05\n",
      "  4238.46 4211.28 4280.51 4635.9  4393.85    0.  ]\n",
      " [4324.62 4004.62 4293.85 4148.72 4342.05 4586.67 4097.44 4638.97 4210.77\n",
      "  4226.67 4207.69 4279.49 4632.82 4384.1     0.  ]\n",
      " [4327.69 4006.67 4295.38 4156.41 4336.92 4583.59 4096.92 4630.26 4207.69\n",
      "  4222.05 4206.67 4282.05 4628.72 4389.23    0.  ]\n",
      " [4328.72 4011.79 4296.41 4155.9  4343.59 4582.56 4097.44 4630.77 4217.44\n",
      "  4235.38 4210.77 4287.69 4632.31 4396.41    0.  ]\n",
      " [4326.15 4011.79 4292.31 4151.28 4347.69 4586.67 4095.9  4627.69 4210.77\n",
      "  4244.1  4212.82 4288.21 4632.82 4398.46    0.  ]]\n",
      ">deleted 0 rows\n",
      ">deleted 1 rows\n",
      ">deleted 2 rows\n",
      ">deleted 1 rows\n",
      ">deleted 0 rows\n",
      ">deleted 142 rows\n",
      ">deleted 0 rows\n",
      ">deleted 48 rows\n",
      ">deleted 0 rows\n",
      ">deleted 153 rows\n",
      ">deleted 0 rows\n",
      ">deleted 43 rows\n",
      ">deleted 0 rows\n",
      ">deleted 0 rows\n",
      ">deleted 0 rows\n",
      ">deleted 15 rows\n",
      ">deleted 0 rows\n",
      ">deleted 5 rows\n",
      ">deleted 10 rows\n",
      ">deleted 0 rows\n",
      ">deleted 21 rows\n",
      ">deleted 53 rows\n",
      ">deleted 0 rows\n",
      ">deleted 12 rows\n",
      ">deleted 58 rows\n",
      ">deleted 53 rows\n",
      ">deleted 0 rows\n",
      ">deleted 59 rows\n"
     ]
    }
   ],
   "source": [
    "root_directory = \"D:\\College\\CS_545\\Final_Project\"\n",
    "fp_csv_file = \"EEG_Eye_State.csv\"\n",
    "data = pd.read_csv(\n",
    "    os.path.join(root_directory, fp_csv_file), delimiter=\",\", usecols=range(15)\n",
    ").dropna(axis=0)\n",
    "\n",
    "# data = pd.read_csv(os.path.join(root_directory, fp_csv_file), header=None)\n",
    "# retrieve data as numpy array\n",
    "values = data.values\n",
    "\n",
    "\n",
    "print(values.shape)\n",
    "print(values[0:5])\n",
    "# step over each EEG column\n",
    "for i in range(values.shape[1] - 1):\n",
    "    # calculate column mean and standard deviation\n",
    "    data_mean, data_std = np.mean(values[:, i]), np.std(values[:, i])\n",
    "    # define outlier bounds\n",
    "    cut_off = data_std * 4\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    # remove too small\n",
    "    too_small = [j for j in range(values.shape[0]) if values[j, i] < lower]\n",
    "    values = np.delete(values, too_small, 0)\n",
    "    print(\">deleted %d rows\" % len(too_small))\n",
    "    # remove too large\n",
    "    too_large = [j for j in range(values.shape[0]) if values[j, i] > upper]\n",
    "    values = np.delete(values, too_large, 0)\n",
    "    print(\">deleted %d rows\" % len(too_large))\n",
    "# save the results to a new file\n",
    "col_labels = [\n",
    "    \"AF3\",\n",
    "    \"F7\",\n",
    "    \"F3\",\n",
    "    \"FC5\",\n",
    "    \"T7\",\n",
    "    \"P7\",\n",
    "    \"O1\",\n",
    "    \"O2\",\n",
    "    \"P8\",\n",
    "    \"T8\",\n",
    "    \"FC6\",\n",
    "    \"F4\",\n",
    "    \"F8\",\n",
    "    \"AF4\",\n",
    "    \"eyeDetection\",\n",
    "]\n",
    "values = pd.DataFrame(values, columns=data.columns)\n",
    "values.to_csv(\n",
    "    \"EEG_Eye_State_No_Outliers.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    index_label=False,\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_NONNUMERIC,\n",
    ")\n",
    "# np.savetxt(\"EEG_Eye_State_No_outliers.csv\", values, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e61655-837e-4b78-9593-28d690219a08",
   "metadata": {},
   "source": [
    "After that I decided to try and investigate the data at a more meta level. I calculated the mean, standard deviation, maximum value, and minimum value for the eye-open state data and eye-closed state data. I also calculated the mean and standard deviation for the data as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73c5bad3-8878-4e7d-b1b2-196a32da76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(file_directory):\n",
    "    data = pd.read_csv(file_directory, delimiter=\",\", usecols=range(15)).dropna(axis=0)\n",
    "\n",
    "    metadata_labels = [\n",
    "        \"Channel\",\n",
    "        \"Mean\",\n",
    "        \"Std\",\n",
    "        \"Eye-Open Mean\",\n",
    "        \"Eye-Open Std\",\n",
    "        \"Eye-Open Max\",\n",
    "        \"Eye-Open Min\",\n",
    "        \"Eye-Closed Mean\",\n",
    "        \"Eye-Closed Std\",\n",
    "        \"Eye-Closed Max\",\n",
    "        \"Eye-Closed Min\",\n",
    "    ]\n",
    "\n",
    "    metadata = [\n",
    "        [\"AF3\"],\n",
    "        [\"F7\"],\n",
    "        [\"F3\"],\n",
    "        [\"FC5\"],\n",
    "        [\"T7\"],\n",
    "        [\"P7\"],\n",
    "        [\"O1\"],\n",
    "        [\"O2\"],\n",
    "        [\"P8\"],\n",
    "        [\"T8\"],\n",
    "        [\"FC6\"],\n",
    "        [\"F4\"],\n",
    "        [\"F8\"],\n",
    "        [\"AF4\"],\n",
    "    ]\n",
    "    values = data.values\n",
    "    print(values.shape)\n",
    "    # step over each EEG column\n",
    "    for i in range(values.shape[1] - 1):\n",
    "        # calculate column mean and standard deviation\n",
    "        data_mean, data_std, data_max, data_min = (\n",
    "            np.mean(values[:, i]),\n",
    "            np.std(values[:, i]),\n",
    "            np.max(values[:, i]),\n",
    "            np.min(values[:, i]),\n",
    "        )\n",
    "        metadata[i].append(data_mean)\n",
    "        metadata[i].append(data_std)\n",
    "\n",
    "    zeros = []\n",
    "    ones = []\n",
    "    for sample in values:\n",
    "        if sample[14] == 0:\n",
    "            zeros.append(sample)\n",
    "        else:\n",
    "            ones.append(sample)\n",
    "    zeros = pd.DataFrame(zeros)\n",
    "    ones = pd.DataFrame(ones)\n",
    "\n",
    "    zeros.columns = data.columns\n",
    "    ones.columns = data.columns\n",
    "    print(zeros.shape)\n",
    "    zeros_values = zeros.values\n",
    "    for i in range(zeros_values.shape[1] - 1):\n",
    "        # calculate column mean and standard deviation\n",
    "        data_mean, data_std, data_max, data_min = (\n",
    "            np.mean(zeros_values[:, i]),\n",
    "            np.std(zeros_values[:, i]),\n",
    "            np.max(zeros_values[:, i]),\n",
    "            np.min(zeros_values[:, i]),\n",
    "        )\n",
    "        metadata[i].append(data_mean)\n",
    "        metadata[i].append(data_std)\n",
    "        metadata[i].append(data_max)\n",
    "        metadata[i].append(data_min)\n",
    "\n",
    "    print(ones.shape)\n",
    "    ones_values = ones.values\n",
    "    for i in range(ones_values.shape[1] - 1):\n",
    "        # calculate column mean and standard deviation\n",
    "        data_mean, data_std, data_max, data_min = (\n",
    "            np.mean(ones_values[:, i]),\n",
    "            np.std(ones_values[:, i]),\n",
    "            np.max(ones_values[:, i]),\n",
    "            np.min(ones_values[:, i]),\n",
    "        )\n",
    "        metadata[i].append(data_mean)\n",
    "        metadata[i].append(data_std)\n",
    "        metadata[i].append(data_max)\n",
    "        metadata[i].append(data_min)\n",
    "    metadata = pd.DataFrame(metadata)\n",
    "    metadata.columns = metadata_labels\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e012b50f-cc3b-4100-927b-dd55e0c004ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14304, 15)\n",
      "(7855, 15)\n",
      "(6449, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Eye-Open Mean</th>\n",
       "      <th>Eye-Open Std</th>\n",
       "      <th>Eye-Open Max</th>\n",
       "      <th>Eye-Open Min</th>\n",
       "      <th>Eye-Closed Mean</th>\n",
       "      <th>Eye-Closed Std</th>\n",
       "      <th>Eye-Closed Max</th>\n",
       "      <th>Eye-Closed Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF3</td>\n",
       "      <td>4298.144530</td>\n",
       "      <td>32.383173</td>\n",
       "      <td>4294.614386</td>\n",
       "      <td>33.537700</td>\n",
       "      <td>4466.15</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4302.444309</td>\n",
       "      <td>30.369437</td>\n",
       "      <td>4441.03</td>\n",
       "      <td>4198.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F7</td>\n",
       "      <td>4007.199968</td>\n",
       "      <td>27.222342</td>\n",
       "      <td>4009.736631</td>\n",
       "      <td>28.256648</td>\n",
       "      <td>4154.36</td>\n",
       "      <td>3924.10</td>\n",
       "      <td>4004.110265</td>\n",
       "      <td>25.569113</td>\n",
       "      <td>4138.97</td>\n",
       "      <td>3913.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F3</td>\n",
       "      <td>4261.656384</td>\n",
       "      <td>16.219297</td>\n",
       "      <td>4260.402014</td>\n",
       "      <td>16.607684</td>\n",
       "      <td>4349.23</td>\n",
       "      <td>4197.44</td>\n",
       "      <td>4263.184229</td>\n",
       "      <td>15.597616</td>\n",
       "      <td>4333.85</td>\n",
       "      <td>4212.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FC5</td>\n",
       "      <td>4120.176654</td>\n",
       "      <td>16.904783</td>\n",
       "      <td>4120.948880</td>\n",
       "      <td>16.536333</td>\n",
       "      <td>4187.18</td>\n",
       "      <td>4073.33</td>\n",
       "      <td>4119.236069</td>\n",
       "      <td>17.296483</td>\n",
       "      <td>4191.79</td>\n",
       "      <td>4067.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T7</td>\n",
       "      <td>4339.673482</td>\n",
       "      <td>11.994233</td>\n",
       "      <td>4339.912341</td>\n",
       "      <td>11.199247</td>\n",
       "      <td>4395.90</td>\n",
       "      <td>4308.72</td>\n",
       "      <td>4339.382548</td>\n",
       "      <td>12.890536</td>\n",
       "      <td>4397.95</td>\n",
       "      <td>4309.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P7</td>\n",
       "      <td>4618.165981</td>\n",
       "      <td>12.923532</td>\n",
       "      <td>4619.437780</td>\n",
       "      <td>13.217759</td>\n",
       "      <td>4671.28</td>\n",
       "      <td>4566.15</td>\n",
       "      <td>4616.616906</td>\n",
       "      <td>12.380614</td>\n",
       "      <td>4672.31</td>\n",
       "      <td>4581.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O1</td>\n",
       "      <td>4070.977384</td>\n",
       "      <td>17.707910</td>\n",
       "      <td>4070.531945</td>\n",
       "      <td>14.417633</td>\n",
       "      <td>4124.10</td>\n",
       "      <td>4027.18</td>\n",
       "      <td>4071.519936</td>\n",
       "      <td>21.018584</td>\n",
       "      <td>4138.97</td>\n",
       "      <td>4026.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O2</td>\n",
       "      <td>4614.060973</td>\n",
       "      <td>14.398261</td>\n",
       "      <td>4613.460053</td>\n",
       "      <td>13.655753</td>\n",
       "      <td>4672.82</td>\n",
       "      <td>4567.18</td>\n",
       "      <td>4614.792904</td>\n",
       "      <td>15.221895</td>\n",
       "      <td>4672.82</td>\n",
       "      <td>4567.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P8</td>\n",
       "      <td>4199.641958</td>\n",
       "      <td>13.807744</td>\n",
       "      <td>4198.939306</td>\n",
       "      <td>12.424151</td>\n",
       "      <td>4255.90</td>\n",
       "      <td>4152.31</td>\n",
       "      <td>4200.497801</td>\n",
       "      <td>15.281592</td>\n",
       "      <td>4255.38</td>\n",
       "      <td>4147.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T8</td>\n",
       "      <td>4229.291521</td>\n",
       "      <td>15.005626</td>\n",
       "      <td>4227.845602</td>\n",
       "      <td>14.217735</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4170.26</td>\n",
       "      <td>4231.052678</td>\n",
       "      <td>15.734208</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4174.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FC6</td>\n",
       "      <td>4199.729761</td>\n",
       "      <td>18.338192</td>\n",
       "      <td>4197.989321</td>\n",
       "      <td>17.985427</td>\n",
       "      <td>4264.10</td>\n",
       "      <td>4125.13</td>\n",
       "      <td>4201.849648</td>\n",
       "      <td>18.539501</td>\n",
       "      <td>4271.28</td>\n",
       "      <td>4130.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>F4</td>\n",
       "      <td>4276.866449</td>\n",
       "      <td>15.089147</td>\n",
       "      <td>4274.783659</td>\n",
       "      <td>15.042807</td>\n",
       "      <td>4329.74</td>\n",
       "      <td>4216.41</td>\n",
       "      <td>4279.403325</td>\n",
       "      <td>14.753427</td>\n",
       "      <td>4332.31</td>\n",
       "      <td>4225.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>F8</td>\n",
       "      <td>4603.123432</td>\n",
       "      <td>25.535726</td>\n",
       "      <td>4599.781686</td>\n",
       "      <td>23.835106</td>\n",
       "      <td>4711.79</td>\n",
       "      <td>4490.77</td>\n",
       "      <td>4607.193740</td>\n",
       "      <td>26.910407</td>\n",
       "      <td>4716.41</td>\n",
       "      <td>4510.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AF4</td>\n",
       "      <td>4358.072562</td>\n",
       "      <td>31.876578</td>\n",
       "      <td>4353.527338</td>\n",
       "      <td>32.223892</td>\n",
       "      <td>4491.28</td>\n",
       "      <td>4236.41</td>\n",
       "      <td>4363.608728</td>\n",
       "      <td>30.548114</td>\n",
       "      <td>4487.69</td>\n",
       "      <td>4246.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel         Mean        Std  Eye-Open Mean  Eye-Open Std  Eye-Open Max  \\\n",
       "0      AF3  4298.144530  32.383173    4294.614386     33.537700       4466.15   \n",
       "1       F7  4007.199968  27.222342    4009.736631     28.256648       4154.36   \n",
       "2       F3  4261.656384  16.219297    4260.402014     16.607684       4349.23   \n",
       "3      FC5  4120.176654  16.904783    4120.948880     16.536333       4187.18   \n",
       "4       T7  4339.673482  11.994233    4339.912341     11.199247       4395.90   \n",
       "5       P7  4618.165981  12.923532    4619.437780     13.217759       4671.28   \n",
       "6       O1  4070.977384  17.707910    4070.531945     14.417633       4124.10   \n",
       "7       O2  4614.060973  14.398261    4613.460053     13.655753       4672.82   \n",
       "8       P8  4199.641958  13.807744    4198.939306     12.424151       4255.90   \n",
       "9       T8  4229.291521  15.005626    4227.845602     14.217735       4287.69   \n",
       "10     FC6  4199.729761  18.338192    4197.989321     17.985427       4264.10   \n",
       "11      F4  4276.866449  15.089147    4274.783659     15.042807       4329.74   \n",
       "12      F8  4603.123432  25.535726    4599.781686     23.835106       4711.79   \n",
       "13     AF4  4358.072562  31.876578    4353.527338     32.223892       4491.28   \n",
       "\n",
       "    Eye-Open Min  Eye-Closed Mean  Eye-Closed Std  Eye-Closed Max  \\\n",
       "0        4206.67      4302.444309       30.369437         4441.03   \n",
       "1        3924.10      4004.110265       25.569113         4138.97   \n",
       "2        4197.44      4263.184229       15.597616         4333.85   \n",
       "3        4073.33      4119.236069       17.296483         4191.79   \n",
       "4        4308.72      4339.382548       12.890536         4397.95   \n",
       "5        4566.15      4616.616906       12.380614         4672.31   \n",
       "6        4027.18      4071.519936       21.018584         4138.97   \n",
       "7        4567.18      4614.792904       15.221895         4672.82   \n",
       "8        4152.31      4200.497801       15.281592         4255.38   \n",
       "9        4170.26      4231.052678       15.734208         4288.21   \n",
       "10       4125.13      4201.849648       18.539501         4271.28   \n",
       "11       4216.41      4279.403325       14.753427         4332.31   \n",
       "12       4490.77      4607.193740       26.910407         4716.41   \n",
       "13       4236.41      4363.608728       30.548114         4487.69   \n",
       "\n",
       "    Eye-Closed Min  \n",
       "0          4198.97  \n",
       "1          3913.33  \n",
       "2          4212.31  \n",
       "3          4067.18  \n",
       "4          4309.74  \n",
       "5          4581.03  \n",
       "6          4026.15  \n",
       "7          4567.69  \n",
       "8          4147.69  \n",
       "9          4174.36  \n",
       "10         4130.77  \n",
       "11         4225.64  \n",
       "12         4510.26  \n",
       "13         4246.15  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_directory = \"D:\\College\\CS_545\\Final_Project\"\n",
    "fp_csv_file = \"EEG_Eye_State_No_Outliers.csv\"\n",
    "metadata = get_metadata(os.path.join(root_directory, fp_csv_file))\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034266ed-f22d-41ab-91cf-731e332f7488",
   "metadata": {},
   "source": [
    "The differences between various channel metadata values in the eye-open versus eye-closed date tended to be very small. They did seem to be present though. Given this I thought it would be interesting to add these values as inputs to the neural network. I thought adding these as a feature might give the neural network some information that would make it easier to identify trends between the states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0585ad-872d-46f9-8e65-36ee2f5bbc73",
   "metadata": {},
   "source": [
    "I started out by just adding the mean and standard deviation for the data as a whole as one of the data points for each sample. To avoid passing information from validate or test into train I first split up the data into train, validate, and test sets. I decided to preserve the temporal ordering this time when splitting up the data. For each of these new datasets I then calculated the overall mean and standard deviation for each channel and added those as column data in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6a93f8a1-1515-4981-bcde-f5e7c93c496b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AF3', 4298.144529502238, 32.383172751002164, 4294.6143857415655,\n",
       "       33.53769989310272, 4466.15, 4206.67, 4302.444309195224,\n",
       "       30.369436627795682, 4441.03, 4198.97], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23268110-f43e-4378-93a6-c985bfdf9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = \"D:\\College\\CS_545\\Final_Project\"\n",
    "fp_csv_file = \"EEG_Eye_State_No_Outliers.csv\"\n",
    "data = pd.read_csv(\n",
    "    os.path.join(root_directory, fp_csv_file), delimiter=\",\", usecols=range(15)\n",
    ").dropna(axis=0)\n",
    "\n",
    "train_fraction = 0.8\n",
    "validate_fraction = 0.1\n",
    "X = (\n",
    "    pd.read_csv(\n",
    "        os.path.join(root_directory, fp_csv_file), delimiter=\",\", usecols=range(15)\n",
    "    )\n",
    "    .dropna(axis=0)\n",
    "    .to_numpy()\n",
    ")\n",
    "n_samples = X.shape[0]\n",
    "\n",
    "n_train = round(n_samples * train_fraction)\n",
    "n_validate = round(n_samples * validate_fraction)\n",
    "\n",
    "col_labels = [\n",
    "    \"AF3\",\n",
    "    \"F7\",\n",
    "    \"F3\",\n",
    "    \"FC5\",\n",
    "    \"T7\",\n",
    "    \"P7\",\n",
    "    \"O1\",\n",
    "    \"O2\",\n",
    "    \"P8\",\n",
    "    \"T8\",\n",
    "    \"FC6\",\n",
    "    \"F4\",\n",
    "    \"F8\",\n",
    "    \"AF4\",\n",
    "    \"eyeDetection\",\n",
    "]\n",
    "Xtrain = X[rows[:n_train], :]\n",
    "Xvalidate = X[rows[n_train : n_train + n_validate], :]\n",
    "Xtest = X[rows[n_train + n_validate :], :]\n",
    "Xtrain = pd.DataFrame(Xtrain, columns=col_labels)\n",
    "Xvalidate = pd.DataFrame(Xvalidate, columns=col_labels)\n",
    "Xtest = pd.DataFrame(Xtest, columns=col_labels)\n",
    "Xtrain = Xtrain.astype({\"eyeDetection\": int})\n",
    "Xvalidate = Xvalidate.astype({\"eyeDetection\": int})\n",
    "Xtest = Xtest.astype({\"eyeDetection\": int})\n",
    "print(Xtrain.iloc[0])\n",
    "print(type(X))\n",
    "Xtrain.to_csv(\n",
    "    \"EEG_Eye_State_Mean_Std_Train.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    index_label=False,\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_NONNUMERIC,\n",
    ")\n",
    "Xvalidate.to_csv(\n",
    "    \"EEG_Eye_State_Mean_Std_Validate.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    index_label=False,\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_NONNUMERIC,\n",
    ")\n",
    "Xtest.to_csv(\n",
    "    \"EEG_Eye_State_Mean_Std_Test.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    index_label=False,\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_NONNUMERIC,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp",
   "language": "python",
   "name": "fp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
