{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import finalprojectneuralnetworks as fpnn\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "with open('Dummy_Test.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    col_labels = [\"AF3\",\"F7\",\"F3\",\"FC5\",\"T7\",\"P7\",\"O1\",\"O2\",\"P8\",\"T8\",\"FC6\",\"F4\",\"F8\",\"AF4\",\"eyeDetection\"]\n",
    "    spamwriter.writerow(col_labels)\n",
    "    list_a = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,0]\n",
    "    list_b = [21,22,23,24,25,26,27,28,29,30,31,32,33,34,1]\n",
    "    for i in range(500):\n",
    "        random_number = random.randint(1, 10)\n",
    "        if random_number > 5:  \n",
    "            spamwriter.writerow(list_a)\n",
    "        else:\n",
    "            spamwriter.writerow(list_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_directory = 'D:\\College\\CS_545\\Final_Project'\n",
    "# fp_csv_file = 'EEG_Eye_State.csv'\n",
    "# train_fraction = 0.8\n",
    "# validate_fraction = 0.1\n",
    "# X = pd.read_csv(os.path.join(root_directory,fp_csv_file), delimiter=',', usecols=range(15)).dropna(axis=0).to_numpy()\n",
    "# n_samples = X.shape[0]\n",
    "# rows = np.arange(n_samples)\n",
    "# np.random.shuffle(rows)\n",
    "\n",
    "# n_train = round(n_samples * train_fraction)\n",
    "# n_validate = round(n_samples * validate_fraction)\n",
    "\n",
    "# col_labels = [\"AF3\",\"F7\",\"F3\",\"FC5\",\"T7\",\"P7\",\"O1\",\"O2\",\"P8\",\"T8\",\"FC6\",\"F4\",\"F8\",\"AF4\",\"eyeDetection\"]\n",
    "# Xtrain = X[rows[:n_train], :]\n",
    "# Xvalidate = X[rows[n_train:n_train + n_validate], :]\n",
    "# Xtest = X[rows[n_train + n_validate:], :]\n",
    "# Xtrain = pd.DataFrame(Xtrain, columns = col_labels)\n",
    "# Xvalidate = pd.DataFrame(Xvalidate, columns = col_labels)\n",
    "# Xtest = pd.DataFrame(Xtest, columns = col_labels)\n",
    "# Xtrain = Xtrain.astype({\"eyeDetection\": int})\n",
    "# Xvalidate = Xvalidate.astype({\"eyeDetection\": int})\n",
    "# Xtest = Xtest.astype({\"eyeDetection\": int})\n",
    "# print(Xtrain.iloc[0])\n",
    "# print( type(X))\n",
    "# Xtrain.to_csv(\"EEG_Eye_State_Train.csv\", encoding='utf-8', index_label=False, index=False, quoting=csv.QUOTE_NONNUMERIC )\n",
    "# Xvalidate.to_csv(\"EEG_Eye_State_Validate.csv\", encoding='utf-8', index_label=False, index=False, quoting=csv.QUOTE_NONNUMERIC )\n",
    "# Xtest.to_csv(\"EEG_Eye_State_Test.csv\", encoding='utf-8', index_label=False, index=False, quoting=csv.QUOTE_NONNUMERIC )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3             4309.74\n",
      "F7              4052.82\n",
      "F3              4285.13\n",
      "FC5             4155.38\n",
      "T7              4369.23\n",
      "P7              4646.67\n",
      "O1              4100.00\n",
      "O2              4649.74\n",
      "P8              4221.54\n",
      "T8              4230.26\n",
      "FC6             4206.15\n",
      "F4              4292.82\n",
      "F8              4598.97\n",
      "AF4             4362.56\n",
      "eyeDetection       0.00\n",
      "Name: 0, dtype: float64\n",
      "0\n",
      "[[4309.74 4052.82 4285.13 4155.38 4369.23 4646.67 4100.   4649.74 4221.54\n",
      "  4230.26 4206.15 4292.82 4598.97 4362.56]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11984, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# root_directory = 'D:\\College\\CS_545\\Final_Project'\n",
    "root_directory = '/s/chopin/l/grad/acf003/CS_545'\n",
    "fp_csv_file = 'EEG_Eye_State_Train.csv'\n",
    "eeg_data = pd.read_csv(os.path.join(root_directory,fp_csv_file), delimiter=',', usecols=range(15)).dropna(axis=0)\n",
    "\n",
    "print(eeg_data.iloc[0, :])\n",
    "open_or_closed = eeg_data.iloc[0, 14]\n",
    "channel_data = eeg_data.iloc[0, 0:14]\n",
    "channel_data = np.array([channel_data])\n",
    "channel_data = channel_data.astype('float').reshape(-1, 14)\n",
    "print(open_or_closed)\n",
    "print(channel_data)\n",
    "eeg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3             float64\n",
      "F7              float64\n",
      "F3              float64\n",
      "FC5             float64\n",
      "T7              float64\n",
      "P7              float64\n",
      "O1              float64\n",
      "O2              float64\n",
      "P8              float64\n",
      "T8              float64\n",
      "FC6             float64\n",
      "F4              float64\n",
      "F8              float64\n",
      "AF4             float64\n",
      "eyeDetection      int64\n",
      "dtype: object\n",
      "AF3             float64\n",
      "F7              float64\n",
      "F3              float64\n",
      "FC5             float64\n",
      "T7              float64\n",
      "P7              float64\n",
      "O1              float64\n",
      "O2              float64\n",
      "P8              float64\n",
      "T8              float64\n",
      "FC6             float64\n",
      "F4              float64\n",
      "F8              float64\n",
      "AF4             float64\n",
      "eyeDetection      int64\n",
      "dtype: object\n",
      "AF3             float64\n",
      "F7              float64\n",
      "F3              float64\n",
      "FC5             float64\n",
      "T7              float64\n",
      "P7              float64\n",
      "O1              float64\n",
      "O2              float64\n",
      "P8              float64\n",
      "T8              float64\n",
      "FC6             float64\n",
      "F4              float64\n",
      "F8              float64\n",
      "AF4             float64\n",
      "eyeDetection      int64\n",
      "dtype: object\n",
      "11984\n"
     ]
    }
   ],
   "source": [
    "# root_directory = 'D:\\College\\CS_545\\Final_Project'\n",
    "root_directory = '/s/chopin/l/grad/acf003/CS_545'\n",
    "\n",
    "train_file = 'EEG_Eye_State_Train.csv'\n",
    "validate_file = 'EEG_Eye_State_Validate.csv'\n",
    "test_file = 'EEG_Eye_State_Test.csv'\n",
    "\n",
    "train_dataset = fpnn.FinalProjectEEGDataset(train_file, root_directory)\n",
    "validate_dataset = fpnn.FinalProjectEEGDataset(validate_file, root_directory)\n",
    "test_dataset = fpnn.FinalProjectEEGDataset(test_file, root_directory)\n",
    "print(train_dataset.__len__())\n",
    "train_dataset.__getitem__(0)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = fpnn.NeuralNetwork(28*28, [512, 512], 10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0102, -0.0323,  0.0691,  0.0265, -0.0896, -0.0404, -0.0841, -0.0201,\n",
      "          0.0491, -0.0167]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Predicted class: tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "print(logits)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    # first = True\n",
    "    for batch, (X, T) in enumerate(dataloader):\n",
    "        X, T = X.to(device), T.to(device)\n",
    "      \n",
    "        # Compute prediction error\n",
    "        Y = model(X.float())\n",
    "        # if first:\n",
    "        #     first = False\n",
    "        #     print('Y.shape', Y.shape)\n",
    "        #     print('T.shape', T.shape)\n",
    "        #     print('T: ', T[0])\n",
    "        loss = loss_fn(Y, T.long())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         if batch % 50 == 0:\n",
    "#             loss, current = loss.item(), batch * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, T in dataloader:\n",
    "            X, T = X.to(device), T.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, T.long()).item()\n",
    "            correct += (pred.argmax(1) == T).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_epochs(epochs, train_dataloader, model, loss_fn, optimizer):\n",
    "    for t in range(epochs):\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        if t % 10 == 0:\n",
    "            print(f\"Epoch {t}\\n-------------------------------\")\n",
    "            test(test_dataloader, model, loss_fn)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fashion_training_data = datasets.FashionMNIST(\n",
    "#     root=\"data\",\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=ToTensor(),\n",
    "# )\n",
    "# fashion_train_dataloader = DataLoader(fashion_training_data, batch_size=64)\n",
    "# n_samples, n_inputs = train_dataset.__len__(), 28*28\n",
    "# n_outputs = 1\n",
    "# n_hiddens = [10, 10]\n",
    "# model = fpnn.NeuralNetwork(28*28, n_hiddens, 10).to(device)\n",
    "# print(model)\n",
    "\n",
    "# learning_rate = 0.5 / (n_samples * n_outputs)  ## Larger learning rate\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# train(fashion_train_dataloader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 14])\n",
      "Shape of y:  torch.Size([64]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 0\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (Linear0): Linear(in_features=14, out_features=500, bias=True)\n",
      "    (ReLU0): ReLU()\n",
      "    (Linear1): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (Linear2): Linear(in_features=500, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 12.534327 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.153025 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 0.677882 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 0.690054 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 0.691178 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_inputs = train_dataset.__len__(), 14\n",
    "n_outputs = 2\n",
    "n_hiddens = [500, 500]\n",
    "model = fpnn.NeuralNetwork(n_inputs, n_hiddens, n_outputs).to(device)\n",
    "print(model)\n",
    "\n",
    "# learning_rate = 0.05 / (n_samples * n_outputs)\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 50\n",
    "train_for_epochs(epochs, train_dataloader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
